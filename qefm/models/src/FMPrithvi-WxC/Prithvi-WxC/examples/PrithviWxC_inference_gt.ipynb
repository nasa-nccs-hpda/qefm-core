{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PrithviWxC\n",
    "\n",
    "This notebook will walk you through how to construct the model,\n",
    "load the weights, build the dataset, and use the model for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from huggingface_hub import hf_hub_download, snapshot_download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now configure the backends and torch states, including setting the seeds for the RNGs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "torch.jit.enable_onednn_fusion(True)\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Using device: {torch.cuda.get_device_name()}\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has approximately 2.3 billion parameters, so it\n",
    "requires reasonable computational resources, but it is possible\n",
    "to run it on a CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/panfs/ccds02/nobackup/people/gtamkin/dev/foundation-models/FMPrithvi-WxC', '/panfs/ccds02/nobackup/people/gtamkin/dev/foundation-models/FMPrithvi-WxC/Prithvi-WxC/examples', '/home/gtamkin/.conda/envs/fusion-conda/lib/python310.zip', '/home/gtamkin/.conda/envs/fusion-conda/lib/python3.10', '/home/gtamkin/.conda/envs/fusion-conda/lib/python3.10/lib-dynload', '', '/home/gtamkin/.local/lib/python3.10/site-packages', '/home/gtamkin/.conda/envs/fusion-conda/lib/python3.10/site-packages', '../']\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.insert(0, \"/panfs/ccds02/nobackup/people/gtamkin/dev/foundation-models/FMPrithvi-WxC\")\n",
    "sys.path.append(\"../\")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "### Variables and times\n",
    "\n",
    "With the environment ready to go, we now need to set up the task.\n",
    "The core model expects a fixed set of variables from the MERRA-2\n",
    "dataset, which are prescribed below. The variables are comprised\n",
    "of surface variables, surface static variables, and variables at\n",
    "various vertical levels within the atmosphere. More details on the\n",
    "MERRA-2 dataset can be found\n",
    "[here](https://gmao.gsfc.nasa.gov/reanalysis/MERRA-2/).\n",
    "\n",
    "The MERRA-2 dataset includes data at longitudes of $-180^\\circ$\n",
    "and $+180^\\circ$. This represents duplicate data, so we set a\n",
    "padding variable to remove it.\n",
    "\n",
    "The input to the core model consists of these variables at two\n",
    "different times. The time difference in hours between these samples\n",
    "is passed to the model and set in the input_time variable.\n",
    "\n",
    "The model's task is to predict the fixed set of variables at a\n",
    "target time, given the input data.\n",
    "\n",
    "For example, if the input times are 0900 and 1200, resulting in\n",
    "an input_time of -3, then a lead_time of 6 would result in a\n",
    "target time of 1800."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_vars = [\n",
    "    \"EFLUX\",\n",
    "    \"GWETROOT\",\n",
    "    \"HFLUX\",\n",
    "    \"LAI\",\n",
    "    \"LWGAB\",\n",
    "    \"LWGEM\",\n",
    "    \"LWTUP\",\n",
    "    \"PS\",\n",
    "    \"QV2M\",\n",
    "    \"SLP\",\n",
    "    \"SWGNT\",\n",
    "    \"SWTNT\",\n",
    "    \"T2M\",\n",
    "    \"TQI\",\n",
    "    \"TQL\",\n",
    "    \"TQV\",\n",
    "    \"TS\",\n",
    "    \"U10M\",\n",
    "    \"V10M\",\n",
    "    \"Z0M\",\n",
    "]\n",
    "static_surface_vars = [\"FRACI\", \"FRLAND\", \"FROCEAN\", \"PHIS\"]\n",
    "vertical_vars = [\"CLOUD\", \"H\", \"OMEGA\", \"PL\", \"QI\", \"QL\", \"QV\", \"T\", \"U\", \"V\"]\n",
    "levels = [\n",
    "    34.0,\n",
    "    39.0,\n",
    "    41.0,\n",
    "    43.0,\n",
    "    44.0,\n",
    "    45.0,\n",
    "    48.0,\n",
    "    51.0,\n",
    "    53.0,\n",
    "    56.0,\n",
    "    63.0,\n",
    "    68.0,\n",
    "    71.0,\n",
    "    72.0,\n",
    "]\n",
    "padding = {\"level\": [0, 0], \"lat\": [0, -1], \"lon\": [0, 0]}\n",
    "\n",
    "lead_times = [6]  # This varibale can be change to change the task\n",
    "input_times = [-6]  # This varibale can be change to change the task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data file\n",
    "MERRA-2 data is available from 1980 to the present day,\n",
    "at 3-hour temporal resolution. The dataloader we have provided\n",
    "expects the surface data and vertical data to be saved in\n",
    "separate files, and when provided with the directories, will\n",
    "search for the relevant data that falls within the provided time range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ef553b63e44e458e6f4b73ba191391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc8a1db646e41eb95aea3bcdc6b037e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/panfs/ccds02/nobackup/people/gtamkin/dev/foundation-models/FMPrithvi-WxC/Prithvi-WxC/examples'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_range = (\"2020-01-01T00:00:00\", \"2020-01-01T23:59:59\")\n",
    "\n",
    "surf_dir = Path(\"./merra-2\")\n",
    "snapshot_download(\n",
    "    repo_id=\"Prithvi-WxC/prithvi.wxc.2300m.v1\",\n",
    "    allow_patterns=\"merra-2/MERRA2_sfc_2020010[1].nc\",\n",
    "    local_dir=\".\",\n",
    ")\n",
    "\n",
    "vert_dir = Path(\"./merra-2\")\n",
    "snapshot_download(\n",
    "    repo_id=\"Prithvi-WxC/prithvi.wxc.2300m.v1\",\n",
    "    allow_patterns=\"merra-2/MERRA_pres_2020010[1].nc\",\n",
    "    local_dir=\".\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climatology\n",
    "The PrithviWxC model was trained to calculate the output by\n",
    "producing a perturbation to the climatology at the target time.\n",
    " This mode of operation is set via the `residual=climate` option.\n",
    " This was chosen as climatology is typically a strong prior for\n",
    " long-range prediction. When using the `residual=climate` option,\n",
    " we have to provide the dataloader with the path of the\n",
    " climatology data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cfe6c0590bd444f9af9a71b0114ed40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323e34f7f65041118d274b7e9a067ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/panfs/ccds02/nobackup/people/gtamkin/dev/foundation-models/FMPrithvi-WxC/Prithvi-WxC/examples'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surf_clim_dir = Path(\"./climatology\")\n",
    "snapshot_download(\n",
    "    repo_id=\"Prithvi-WxC/prithvi.wxc.2300m.v1\",\n",
    "    allow_patterns=\"climatology/climate_surface_doy00[1]*.nc\",\n",
    "    local_dir=\".\",\n",
    ")\n",
    "\n",
    "vert_clim_dir = Path(\"./climatology\")\n",
    "snapshot_download(\n",
    "    repo_id=\"Prithvi-WxC/prithvi.wxc.2300m.v1\",\n",
    "    allow_patterns=\"climatology/climate_vertical_doy00[1]*.nc\",\n",
    "    local_dir=\".\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postion encoding\n",
    "Position data is included in the data passed to the model,\n",
    "as this allows the attention mechanism to determine data\n",
    "locality rather than explicit or implicit data connections.\n",
    "The position data is encoded in the model with two possible\n",
    "options, fourier or absolute. As these encoding options\n",
    "require different treatment within the data loader, the\n",
    "chosen option is set here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_encoding = \"fourier\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset init\n",
    "We can now instantiate the MERRA2 Dataset class provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PrithviWxC.dataloaders.merra2 import Merra2Dataset\n",
    "\n",
    "dataset = Merra2Dataset(\n",
    "    time_range=time_range,\n",
    "    lead_times=lead_times,\n",
    "    input_times=input_times,\n",
    "    data_path_surface=surf_dir,\n",
    "    data_path_vertical=vert_dir,\n",
    "    climatology_path_surface=surf_clim_dir,\n",
    "    climatology_path_vertical=vert_clim_dir,\n",
    "    surface_vars=surface_vars,\n",
    "    static_surface_vars=static_surface_vars,\n",
    "    vertical_vars=vertical_vars,\n",
    "    levels=levels,\n",
    "    positional_encoding=positional_encoding,\n",
    ")\n",
    "assert len(dataset) > 0, \"There doesn't seem to be any valid data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model\n",
    "We are now ready to build the mdoel.\n",
    "### Scalers\n",
    "Additionally, the model takes as static parameters the mean\n",
    "and variance values of the input variables and the variance\n",
    "values of the target difference, i.e., the variance between\n",
    "climatology and instantaneous variables. We have provided\n",
    "data files containing these values, and here we load this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PrithviWxC.dataloaders.merra2 import (\n",
    "    input_scalers,\n",
    "    output_scalers,\n",
    "    static_input_scalers,\n",
    ")\n",
    "\n",
    "surf_in_scal_path = Path(\"./climatology/musigma_surface.nc\")\n",
    "hf_hub_download(\n",
    "    repo_id=\"Prithvi-WxC/prithvi.wxc.2300m.v1\",\n",
    "    filename=f\"climatology/{surf_in_scal_path.name}\",\n",
    "    local_dir=\".\",\n",
    ")\n",
    "\n",
    "vert_in_scal_path = Path(\"./climatology/musigma_vertical.nc\")\n",
    "hf_hub_download(\n",
    "    repo_id=\"Prithvi-WxC/prithvi.wxc.2300m.v1\",\n",
    "    filename=f\"climatology/{vert_in_scal_path.name}\",\n",
    "    local_dir=\".\",\n",
    ")\n",
    "\n",
    "surf_out_scal_path = Path(\"./climatology/anomaly_variance_surface.nc\")\n",
    "hf_hub_download(\n",
    "    repo_id=\"Prithvi-WxC/prithvi.wxc.2300m.v1\",\n",
    "    filename=f\"climatology/{surf_out_scal_path.name}\",\n",
    "    local_dir=\".\",\n",
    ")\n",
    "\n",
    "vert_out_scal_path = Path(\"./climatology/anomaly_variance_vertical.nc\")\n",
    "hf_hub_download(\n",
    "    repo_id=\"Prithvi-WxC/prithvi.wxc.2300m.v1\",\n",
    "    filename=f\"climatology/{vert_out_scal_path.name}\",\n",
    "    local_dir=\".\",\n",
    ")\n",
    "\n",
    "in_mu, in_sig = input_scalers(\n",
    "    surface_vars,\n",
    "    vertical_vars,\n",
    "    levels,\n",
    "    surf_in_scal_path,\n",
    "    vert_in_scal_path,\n",
    ")\n",
    "\n",
    "output_sig = output_scalers(\n",
    "    surface_vars,\n",
    "    vertical_vars,\n",
    "    levels,\n",
    "    surf_out_scal_path,\n",
    "    vert_out_scal_path,\n",
    ")\n",
    "\n",
    "static_mu, static_sig = static_input_scalers(\n",
    "    surf_in_scal_path,\n",
    "    static_surface_vars,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task and additional configs\n",
    "As previously mentioned, the PrithviWxC model's pretext task\n",
    "involved predicting the desired variable at a specific lead\n",
    "time. This was achieved by calculating the difference (delta)\n",
    "compared to the climatological average at that time. This\n",
    "operational mode is activated using the residual flag. Although\n",
    "the model includes additional residual options, the core model\n",
    "weights were not trained using these modes.\n",
    "\n",
    "Additionally, for training and evaluation, it is possible to\n",
    "mask tokens in the model. The masking occurs after tokenization,\n",
    "prior to the encoder layers. The model utilizes multi-axis\n",
    "attention, with data broken down into a hierarchy of local and\n",
    "global patches. Consequently, masking can be configured to mask\n",
    "either small local patches or larger global patches. This\n",
    "configuration is achieved via the `masking_mode` flag. It is\n",
    "possible to set `masking_mode=both`. This does not mix the modes\n",
    "but rather allows both modes to be used and swapped between,\n",
    "primarily for training purposes. For this demonstration, we will\n",
    "adjust the masking ratio to showcase the reconstruction\n",
    "capabilities of the model.\n",
    "\n",
    "Finally, we can set up shifting. Primarily utilized in the\n",
    "decoder, this enables alternate shifting of the attention\n",
    "windows, similar to the SWIN model. This option necessitates\n",
    "an even number of decoder blocks and is incompatible with the\n",
    "encoder when masking is also employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = \"climate\"\n",
    "masking_mode = \"local\"\n",
    "decoder_shifting = True\n",
    "masking_ratio = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model init\n",
    "We now have all the pieces to build the model. If you are\n",
    "using the pretrained weights, a number of the model\n",
    "hyperparameters are predetermined and included below. With\n",
    "this configuration, the model will have approximately 2.3\n",
    "billion parameters. Therefore, if you want to train the fully\n",
    "unfrozen model, you will likely need to use a model distribution\n",
    "approach, such as fully shared data parallelism (FSDP). To\n",
    "further reduce the memory usage of the model when gradients are\n",
    "required, there are two variables — `checkpoint_encoder` and\n",
    "`checkpoint_decoder` — which enable activation checkpointing of\n",
    "desired transformer layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "from PrithviWxC.model import PrithviWxC\n",
    "\n",
    "hf_hub_download(\n",
    "    repo_id=\"Prithvi-WxC/prithvi.wxc.2300m.v1\",\n",
    "    filename=\"config.yaml\",\n",
    "    local_dir=\".\",\n",
    ")\n",
    "\n",
    "with open(\"./config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "model = PrithviWxC(\n",
    "    in_channels=config[\"params\"][\"in_channels\"],\n",
    "    input_size_time=config[\"params\"][\"input_size_time\"],\n",
    "    in_channels_static=config[\"params\"][\"in_channels_static\"],\n",
    "    input_scalers_mu=in_mu,\n",
    "    input_scalers_sigma=in_sig,\n",
    "    input_scalers_epsilon=config[\"params\"][\"input_scalers_epsilon\"],\n",
    "    static_input_scalers_mu=static_mu,\n",
    "    static_input_scalers_sigma=static_sig,\n",
    "    static_input_scalers_epsilon=config[\"params\"][\n",
    "        \"static_input_scalers_epsilon\"\n",
    "    ],\n",
    "    output_scalers=output_sig**0.5,\n",
    "    n_lats_px=config[\"params\"][\"n_lats_px\"],\n",
    "    n_lons_px=config[\"params\"][\"n_lons_px\"],\n",
    "    patch_size_px=config[\"params\"][\"patch_size_px\"],\n",
    "    mask_unit_size_px=config[\"params\"][\"mask_unit_size_px\"],\n",
    "    mask_ratio_inputs=masking_ratio,\n",
    "    embed_dim=config[\"params\"][\"embed_dim\"],\n",
    "    n_blocks_encoder=config[\"params\"][\"n_blocks_encoder\"],\n",
    "    n_blocks_decoder=config[\"params\"][\"n_blocks_decoder\"],\n",
    "    mlp_multiplier=config[\"params\"][\"mlp_multiplier\"],\n",
    "    n_heads=config[\"params\"][\"n_heads\"],\n",
    "    dropout=config[\"params\"][\"dropout\"],\n",
    "    drop_path=config[\"params\"][\"drop_path\"],\n",
    "    parameter_dropout=config[\"params\"][\"parameter_dropout\"],\n",
    "    residual=residual,\n",
    "    masking_mode=masking_mode,\n",
    "    decoder_shifting=decoder_shifting,\n",
    "    positional_encoding=positional_encoding,\n",
    "    checkpoint_encoder=[],\n",
    "    checkpoint_decoder=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights\n",
    "We have provided unshared pretrained weights for the model,\n",
    "which can now be loaded. The model can then be transferred\n",
    "to the requested device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weights/prithvi.wxc.2300m.v1.pt'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_path = Path(\"./weights/prithvi.wxc.2300m.v1.pt\")\n",
    "hf_hub_download(\n",
    "    repo_id=\"Prithvi-WxC/prithvi.wxc.2300m.v1\",\n",
    "    filename=weights_path.name,\n",
    "    local_dir=\"./weights\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 31.73 GiB of which 96.69 MiB is free. Process 3712637 has 2.50 GiB memory in use. Process 3994282 has 986.00 MiB memory in use. Process 165441 has 22.92 GiB memory in use. Including non-PyTorch memory, this process has 5.25 GiB memory in use. Of the allocated memory 4.94 GiB is allocated by PyTorch, and 15.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(state_dict, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m model\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m!=\u001b[39m device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m      7\u001b[0m     model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m ):\n\u001b[0;32m----> 9\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 900 (5 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 31.73 GiB of which 96.69 MiB is free. Process 3712637 has 2.50 GiB memory in use. Process 3994282 has 986.00 MiB memory in use. Process 165441 has 22.92 GiB memory in use. Including non-PyTorch memory, this process has 5.25 GiB memory in use. Of the allocated memory 4.94 GiB is allocated by PyTorch, and 15.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load(weights_path, weights_only=False)\n",
    "if \"model_state\" in state_dict:\n",
    "    state_dict = state_dict[\"model_state\"]\n",
    "model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "if (hasattr(model, \"device\") and model.device != device) or not hasattr(\n",
    "    model, \"device\"\n",
    "):\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "We are now ready to perform inference on the model. The data\n",
    "returned from the dataset class requires additional\n",
    "preprocessing; therefore, after polling the dataset, we process\n",
    "the data using the `preproc` function. This processed data is\n",
    "then transferred to the device. To recover the masking, we can\n",
    "save the torch RNG state and use it later. Finally, we run the\n",
    "model in evaluation mode without generating the gradient graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PrithviWxC.dataloaders.merra2 import preproc\n",
    "\n",
    "data = next(iter(dataset))\n",
    "batch = preproc([data], padding)\n",
    "\n",
    "for k, v in batch.items():\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        batch[k] = v.to(device)\n",
    "\n",
    "rng_state_1 = torch.get_rng_state()\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    out = model(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m = out[0, 12].cpu().numpy()\n",
    "\n",
    "lat = np.linspace(-90, 90, out.shape[-2])\n",
    "lon = np.linspace(-180, 180, out.shape[-1])\n",
    "X, Y = np.meshgrid(lon, lat)\n",
    "\n",
    "plt.contourf(X, Y, t2m, 100)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-fusion-conda]",
   "language": "python",
   "name": "conda-env-.conda-fusion-conda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
